# Cost-function
In this repository, we implement and explore the cost function for linear regression with one variable.
Этот код — из курса по машинному обучению (Andrew Ng, Coursera), где демонстрируется графическая интуиция для линейной регрессии. Давай подробно разберём его **построчно**.  

***

### Импорт библиотек
```python
import numpy as np
%matplotlib widget
import matplotlib.pyplot as plt
from lab_utils_uni import plt_intuition, plt_stationary, plt_update_onclick, soup_bowl
```
- `import numpy as np` — импортируем библиотеку NumPy для работы с массивами и числовыми вычислениями.  
- `%matplotlib widget` — Jupyter Notebook *магическая команда*. Делает графики Matplotlib *интерактивными* (можно кликать и обновлять графики прямо в окне).  
- `import matplotlib.pyplot as plt` — импортируем Matplotlib для построения графиков.  
- `from lab_utils_uni import ...` — импорт функций из вспомогательного модуля (`lab_utils_uni.py`), подготовленного авторами курса:
  - `plt_intuition` — рисует интуитивный график линейной регрессии (прямая + точки).  
  - `plt_stationary` — строит статичный график для работы с данными.  
  - `plt_update_onclick` — позволяет обновлять график при клике (менять параметры линейной регрессии).  
  - `soup_bowl` — отображает "чашу супа" (график функции стоимости в 3D), иллюстрирующий минимум ошибки.  

***

### Создание обучающих данных
```python
x_train = np.array([1.0, 2.0])
y_train = np.array([300.0, 500.0])
```
- `x_train` — массив значений признака (например, площадь квартиры).  
- `y_train` — массив целевых значений (например, цена квартиры).  
  Здесь задаются всего два примера: площадь $$1.0$$ и $$2.0$$, соответствующие ценам $$300$$ и $$500$$.  

***

### Функция стоимости (Cost Function)
```python
def compute_cost(x, y, w, b): 
    m = x.shape[0] 
    cost_sum = 0 
    for i in range(m): 
        f_wb = w * x[i] + b   
        cost = (f_wb - y[i]) ** 2  
        cost_sum = cost_sum + cost  
    total_cost = (1 / (2 * m)) * cost_sum  
    return total_cost
```
- `def compute_cost(x, y, w, b):` — определяем функцию для вычисления стоимости (Mean Squared Error с коэффициентом 1/2).  
- `m = x.shape` — получаем количество обучающих примеров.
- `cost_sum = 0` — инициализация суммы ошибок.  
- `for i in range(m):` — пробегаем по всем примерам.  
- `f_wb = w * x[i] + b` — вычисляем предсказание гипотезы (линейная модель).  
- `cost = (f_wb - y[i]) ** 2` — считаем квадрат ошибки каждого примера.  
- `cost_sum = cost_sum + cost` — суммируем ошибки.  
- `total_cost = (1 / (2 * m)) * cost_sum` — усредняем ошибку по всем примерам и умножаем на 1/2.  
- `return total_cost` — возвращаем итоговую стоимость.  

***

### Визуализация интуиции
```python
plt_intuition(x_train, y_train)
```
- Строится график точек $$ (x, y) $$ и прямая (линейная регрессия) для интуитивного понимания.  

***

### Новые тренировочные данные
```python
x_train = np.array([1.0, 1.7, 2.0, 2.5, 3.0, 3.2])
y_train = np.array([250, 300, 480,  430,   630, 730,])
```
- Создаем новый набор данных из 6 точек. Теперь наша база чуть "реалистичнее".  

***

### Закрытие старых графиков
```python
plt.close('all')
```
- Закрывает все ранее открытые графики Matplotlib (нужно, чтобы старые фигуры не мешались новым).  

***

### Создание статичной визуализации
```python
fig, ax, dyn_items = plt_stationary(x_train, y_train)
```
- `plt_stationary` строит график с точками и «заготовленной» линией.  
- `fig, ax` — стандартные объекты Figure и Axes в Matplotlib.  
- `dyn_items` — динамические элементы (например, сама линия, предсказания и легенды), которые будут обновляться.  

***

### Добавление интерактивности
```python
updater = plt_update_onclick(fig, ax, x_train, y_train, dyn_items)
```
- Связывает график с функцией обновления: теперь при клике мышкой будут изменяться параметры $$w$$ и $$b$$, и пересчитываться линия регрессии/ошибка.  

***

### Визуализация функции стоимости
```python
soup_bowl()
```
- Показывает 3D-график стоимости $$J(w, b)$$.  
- Поверхность напоминает «чашу супа», у которой минимум находится в центре: именно туда должен стремиться градиентный спуск.  

***
